{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTMap\n",
    "\n",
    "This is a notebook to show how the prototype `htmap` library (https://github.com/htcondor/htmap) works.\n",
    "\n",
    "If you've messed up your cache directory somehow, running `htmap.clean()` will delete everything so you can start fresh.\n",
    "Note that each map call is given a `tag`, which are unique.\n",
    "To run a new map with the same `tag`, you must remove the old one.\n",
    "Tools for managing existing maps are shown in the section on management, after going through the interface sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import htmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmap.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells control which delivery method is used to get Python to the execute node. Whichever cell is run last wins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to 'assume' delivery\n",
    "htmap.settings['DELIVERY_METHOD'] = 'assume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to 'docker' delivery\n",
    "htmap.settings['DELIVERY_METHOD'] = 'docker'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Interface (`map`-like)\n",
    "\n",
    "`htmap` currently has two interfaces. The first is a very \"functional\", map-based interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double(x):\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's built-in `map` function works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubled = list(map(double, range(10)))\n",
    "doubled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the same with `htmap`, we just use the `map` function it provides instead. Note that `htmap` has persistence for completed jobs, so if you get a `clusterid` of `None`, you already have the outputs for all of your inputs cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapResult(tag = double)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = htmap.map('double', double, range(10))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That function returns a `MapResult` which we can use to get information about the running jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a snapshot of the map progress by using the `status()` method on the `MapResult`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map double (10 inputs): Held = 0 | Idle = 10 | Run = 0 | Done = 0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait on the results of the map with a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "double: 100%|################################| 10/10 [00:06<00:00,  1.99input/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0, 6, 25955)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.wait(show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the results, we iterate over the `MapResult` (passing it into the `list` constructor does this internally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubled_htc = list(result)\n",
    "doubled_htc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Interface w/ Decorator\n",
    "\n",
    "The second interface has the same functional flavor to it, but uses a decorator on the function itself.\n",
    "\n",
    "For those who care, the first interface is doing the same thing, but just hides the decorator from you.\n",
    "\n",
    "I'll also use a slightly more complicated function to show off some other features. This function has two arguments, and one of them is a keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MappedFunction(func = <function power at 0x7fb974006840>, map_options = {'request_memory': '100MB', 'request_disk': '1GB'})>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@htmap.mapped\n",
    "def power(x, p = 1):\n",
    "    return x ** p\n",
    "\n",
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `power` is not actually a function, but instead a `MappedFunction` which has a reference to the real function inside it. Because of Python voodoo, you can still call it like a normal function, running entirely locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't use `map` now because it only accepts a one-dimensional input. Instead, we'll use `starmap`. Both `map` and `starmap` are now methods of the `MappedFunction` object. That does mean we have to contort things a little so that we're passing lists of tuples and dictionaries to `starmap`, which looks a little weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapResult(tag = power)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [(x,) for x in range(10)]\n",
    "powers = [{'p': p} for p in range(10)]\n",
    "\n",
    "power_result = power.starmap('power', xs, powers)\n",
    "power_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate over the result ourselves. By doing it this way, they'll come back in order as soon as possible. The outputs should be 0^0, 1^1, 2^2, 3^3, etc. We'll use the `iter_with_inputs` method to see how the inputs are mapped to the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0,), {'p': 0}) -> 1\n",
      "((1,), {'p': 1}) -> 1\n",
      "((2,), {'p': 2}) -> 4\n",
      "((3,), {'p': 3}) -> 27\n",
      "((4,), {'p': 4}) -> 256\n",
      "((5,), {'p': 5}) -> 3125\n",
      "((6,), {'p': 6}) -> 46656\n",
      "((7,), {'p': 7}) -> 823543\n",
      "((8,), {'p': 8}) -> 16777216\n",
      "((9,), {'p': 9}) -> 387420489\n"
     ]
    }
   ],
   "source": [
    "for inp, out in power_result.iter_with_inputs():\n",
    "    print(f'{inp} -> {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping Interface\n",
    "\n",
    "The other interface is built to look like the same looping constructs that people are probably using before they start doing any HTC.\n",
    "\n",
    "It relies on Python's `with` statement, which lets you run code before and after a block of code runs. It looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple(x):\n",
    "    return 3 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapResult(tag = triple)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with htmap.build_map('triple', triple) as map_builder:\n",
    "    for x in range(10):\n",
    "        map_builder(x)\n",
    "        \n",
    "triple_result = map_builder.result\n",
    "triple_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that once we create the `MapBuilder`, stored in the variable `map_builder`, we can just call it as if it was the function we wanted to do a map on. The `MapBuilder` catches the calls and feeds them into the same backend that does the mapping above. I really like this because it's super-simple: you don't need to do anything weird with the arguments to fit them into the right shape for the map. If you can call your function normally, you can slap it in this `with` block, replace it with the `MapBuilder`, and do the map.\n",
    "\n",
    "This time we'll iterate in an unordered way, as jobs come back (the previous iterators went in order, as available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for r in triple_result.iter_as_available():\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping Interface w/ Decorator\n",
    "\n",
    "Again, it's essentially the same, it's just that `build_map` is a method of the decorated function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@htmap.mapped\n",
    "def quadruple(x):\n",
    "    return 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapResult(tag = quadruple)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with quadruple.build_map('quadruple') as map_builder:\n",
    "    for x in range(10):\n",
    "        map_builder(x)\n",
    "        \n",
    "quadruple_result = map_builder.result\n",
    "quadruple_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "8\n",
      "12\n",
      "16\n",
      "20\n",
      "24\n",
      "28\n",
      "32\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for r in quadruple_result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Maps\n",
    "\n",
    "You can interact with the jobs behind a map by calling methods on the `MapResult`. Let's define a sleepy function so that we have time to interact with the jobs while they're running.\n",
    "\n",
    "I'll use the command line `condor_q` here to prove that it's really working, along with the `MapResult`'s own `status()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@htmap.mapped\n",
    "def sleep_and_double(x):\n",
    "    time.sleep(10)\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can kill all the jobs associated with a `MapResult` using the `remove()` method.\n",
    "This also removes all of the input, output, and log files associated with that map.\n",
    "Therefore, this also frees up the `tag` to use for another map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- Schedd: jupyter0000.chtc.wisc.edu : <127.0.0.1:9618?... @ 10/04/18 09:58:40\n",
      "OWNER  BATCH_NAME    SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS\n",
      "karpel sleepy      10/4  09:58      _      _     10     10 1395.0-9\n",
      "\n",
      "Total for query: 10 jobs; 0 completed, 0 removed, 10 idle, 0 running, 0 held, 0 suspended \n",
      "Total for karpel: 10 jobs; 0 completed, 0 removed, 10 idle, 0 running, 0 held, 0 suspended \n",
      "Total for all users: 16 jobs; 0 completed, 0 removed, 10 idle, 0 running, 6 held, 0 suspended\n",
      "\n",
      "Map sleepy (10 inputs): Held = 0 | Idle = 10 | Run = 0 | Done = 0\n",
      "\n",
      "\n",
      "-- Schedd: jupyter0000.chtc.wisc.edu : <127.0.0.1:9618?... @ 10/04/18 09:58:43\n",
      "OWNER BATCH_NAME      SUBMITTED   DONE   RUN    IDLE   HOLD  TOTAL JOB_IDS\n",
      "\n",
      "Total for query: 0 jobs; 0 completed, 0 removed, 0 idle, 0 running, 0 held, 0 suspended \n",
      "Total for karpel: 0 jobs; 0 completed, 0 removed, 0 idle, 0 running, 0 held, 0 suspended \n",
      "Total for all users: 6 jobs; 0 completed, 0 removed, 0 idle, 0 running, 6 held, 0 suspended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sleepy_result = sleep_and_double.map('sleepy', range(10))\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "!condor_q\n",
    "print(sleepy_result.status())\n",
    "\n",
    "sleepy_result.remove()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "!condor_q\n",
    "# print(sleepy_result.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also hold and release jobs (and the rest of the job actions, but I won't go over them here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- Schedd: jupyter0000.chtc.wisc.edu : <127.0.0.1:9618?... @ 10/04/18 09:58:46\n",
      "OWNER  BATCH_NAME    SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS\n",
      "karpel sleepy      10/4  09:58      _      _     10     10 1396.0-9\n",
      "\n",
      "Total for query: 10 jobs; 0 completed, 0 removed, 10 idle, 0 running, 0 held, 0 suspended \n",
      "Total for karpel: 10 jobs; 0 completed, 0 removed, 10 idle, 0 running, 0 held, 0 suspended \n",
      "Total for all users: 16 jobs; 0 completed, 0 removed, 10 idle, 0 running, 6 held, 0 suspended\n",
      "\n",
      "Map sleepy (10 inputs): Held = 0 | Idle = 10 | Run = 0 | Done = 0\n",
      " Input Index │ Hold Reason Code │                Hold Reason                \n",
      "─────────────┼──────────────────┼───────────────────────────────────────────\n",
      "      0      │        1         │ Python-initiated action. (by user karpel)\n",
      "      1      │        1         │ Python-initiated action. (by user karpel)\n",
      "      2      │        1         │ Python-initiated action. (by user karpel)\n",
      "      3      │        1         │ Python-initiated action. (by user karpel)\n",
      "      4      │        1         │ Python-initiated action. (by user karpel)\n",
      "      5      │        1         │ Python-initiated action. (by user karpel)\n",
      "      6      │        1         │ Python-initiated action. (by user karpel)\n",
      "      7      │        1         │ Python-initiated action. (by user karpel)\n",
      "      8      │        1         │ Python-initiated action. (by user karpel)\n",
      "      9      │        1         │ Python-initiated action. (by user karpel)\n",
      "─────────────┴──────────────────┴───────────────────────────────────────────\n",
      "\n",
      "\n",
      "-- Schedd: jupyter0000.chtc.wisc.edu : <127.0.0.1:9618?... @ 10/04/18 09:58:47\n",
      "OWNER  BATCH_NAME    SUBMITTED   DONE   RUN    IDLE   HOLD  TOTAL JOB_IDS\n",
      "karpel sleepy      10/4  09:58      _      _      _     10     10 1396.0-9\n",
      "\n",
      "Total for query: 10 jobs; 0 completed, 0 removed, 0 idle, 0 running, 10 held, 0 suspended \n",
      "Total for karpel: 10 jobs; 0 completed, 0 removed, 0 idle, 0 running, 10 held, 0 suspended \n",
      "Total for all users: 16 jobs; 0 completed, 0 removed, 0 idle, 0 running, 16 held, 0 suspended\n",
      "\n",
      "Map sleepy (10 inputs): Held = 10 | Idle = 0 | Run = 0 | Done = 0\n",
      "\n",
      "\n",
      "-- Schedd: jupyter0000.chtc.wisc.edu : <127.0.0.1:9618?... @ 10/04/18 09:58:48\n",
      "OWNER  BATCH_NAME    SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS\n",
      "karpel sleepy      10/4  09:58      _      _     10     10 1396.0-9\n",
      "\n",
      "Total for query: 10 jobs; 0 completed, 0 removed, 10 idle, 0 running, 0 held, 0 suspended \n",
      "Total for karpel: 10 jobs; 0 completed, 0 removed, 10 idle, 0 running, 0 held, 0 suspended \n",
      "Total for all users: 16 jobs; 0 completed, 0 removed, 10 idle, 0 running, 6 held, 0 suspended\n",
      "\n",
      "Map sleepy (10 inputs): Held = 0 | Idle = 10 | Run = 0 | Done = 0\n"
     ]
    }
   ],
   "source": [
    "sleepy_result = sleep_and_double.map('sleepy', range(10))\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "!condor_q\n",
    "print(sleepy_result.status())\n",
    "\n",
    "hold_output = sleepy_result.hold()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "print(sleepy_result.hold_reasons())\n",
    "\n",
    "!condor_q\n",
    "print(sleepy_result.status())\n",
    "\n",
    "sleepy_result.release()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "!condor_q\n",
    "print(sleepy_result.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map ID Management\n",
    "\n",
    "To get a list of all of the `tag`s you have stored, do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('double', 'quadruple', 'sleepy', 'triple', 'power')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps = htmap.tags()\n",
    "maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the status of all your maps using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Map ID  │ Held │ Idle │ Run │ Done │   Data  \n",
      "───────────┼──────┼──────┼─────┼──────┼─────────\n",
      "   double  │  0   │  0   │  0  │  10  │ 21.5 KB\n",
      " quadruple │  0   │  0   │  0  │  10  │ 21.5 KB\n",
      "   sleepy  │  0   │  10  │  0  │  0   │  6.0 KB\n",
      "   triple  │  0   │  0   │  0  │  10  │ 21.0 KB\n",
      "   power   │  0   │  0   │  0  │  10  │ 21.7 KB\n",
      "───────────┴──────┴──────┴─────┴──────┴─────────\n"
     ]
    }
   ],
   "source": [
    "print(htmap.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover an existing `tag`, use the module-level `recover` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "recovered_result = htmap.recover(maps[0])\n",
    "print(list(recovered_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "Let's make a job that we know will experience an exception on the execute node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@htmap.mapped\n",
    "def bad(x):\n",
    "    return x / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapResult(tag = bad)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_result = bad.map('bad', range(10))\n",
    "bad_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the maps to finish. We can't use the `wait()` method because we aren't going to manage to produce any output files, which is what it's watching for. Instead, look at the cluster log (this runs forever, so you'll need to cancel the cell at some point using the black box in the notebook menu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 (1397.000.000) 10/04 09:59:14 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "001 (1397.001.000) 10/04 09:59:14 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "007 (1397.000.000) 10/04 09:59:16 Shadow exception!\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1682604/d238998870ae18a399d03477dad0c0a8.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:22031>\n",
      "\t1248  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.000.000) 10/04 09:59:16 Job was held.\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1682604/d238998870ae18a399d03477dad0c0a8.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:22031>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "007 (1397.001.000) 10/04 09:59:16 Shadow exception!\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1682631/635f1664f168e2a15b8e43f20d45154b.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:10737>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.001.000) 10/04 09:59:16 Job was held.\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1682631/635f1664f168e2a15b8e43f20d45154b.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:10737>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "001 (1397.002.000) 10/04 09:59:17 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "001 (1397.003.000) 10/04 09:59:17 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "007 (1397.002.000) 10/04 09:59:18 Shadow exception!\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683033/dbed6abf8fcf4beec7fc97f3170de3cc.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:5574>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.002.000) 10/04 09:59:18 Job was held.\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683033/dbed6abf8fcf4beec7fc97f3170de3cc.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:5574>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "007 (1397.003.000) 10/04 09:59:18 Shadow exception!\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683036/a2adfb888921eca44a056e5614bdced1.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:16586>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.003.000) 10/04 09:59:18 Job was held.\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683036/a2adfb888921eca44a056e5614bdced1.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:16586>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "001 (1397.004.000) 10/04 09:59:19 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "001 (1397.005.000) 10/04 09:59:20 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "007 (1397.004.000) 10/04 09:59:21 Shadow exception!\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683361/7415a204e528373efb30f701721bed02.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:22606>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "007 (1397.005.000) 10/04 09:59:21 Shadow exception!\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683364/7dc2b60572fdeebaeaafe98be96685fe.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:31713>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.004.000) 10/04 09:59:21 Job was held.\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683361/7415a204e528373efb30f701721bed02.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:22606>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "012 (1397.005.000) 10/04 09:59:21 Job was held.\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683364/7dc2b60572fdeebaeaafe98be96685fe.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:31713>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "001 (1397.006.000) 10/04 09:59:22 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "001 (1397.007.000) 10/04 09:59:22 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "007 (1397.006.000) 10/04 09:59:23 Shadow exception!\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683683/8afba1d2b4cf04a8c6e42dd72dcd48b7.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:17677>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.006.000) 10/04 09:59:23 Job was held.\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683683/8afba1d2b4cf04a8c6e42dd72dcd48b7.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:17677>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "007 (1397.007.000) 10/04 09:59:23 Shadow exception!\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683684/22f4eed5a0f8b5e3959b9535a7a12870.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:8696>\n",
      "\t1197  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.007.000) 10/04 09:59:23 Job was held.\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1683684/22f4eed5a0f8b5e3959b9535a7a12870.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:8696>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "001 (1397.008.000) 10/04 09:59:25 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "001 (1397.009.000) 10/04 09:59:25 Job executing on host: <127.0.0.1:9618?addrs=127.0.0.1-9618+[2607-f388-107c-501-216-3eff-fe0f-5959]-9618&noUDP&sock=1015_c8b7_4>\n",
      "...\n",
      "007 (1397.008.000) 10/04 09:59:26 Shadow exception!\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1684002/bbafd5d2fe7959784ff44e7ba3e8af7c.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:32741>\n",
      "\t1248  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.008.000) 10/04 09:59:26 Job was held.\n",
      "\tError from slot3@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1684002/bbafd5d2fe7959784ff44e7ba3e8af7c.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:32741>\n",
      "\tCode 13 Subcode 2\n",
      "...\n",
      "007 (1397.009.000) 10/04 09:59:26 Shadow exception!\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1684033/e8a41bf8f29419bd7e9ee45ddab9fae1.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:31528>\n",
      "\t1248  -  Run Bytes Sent By Job\n",
      "\t2512  -  Run Bytes Received By Job\n",
      "...\n",
      "012 (1397.009.000) 10/04 09:59:26 Job was held.\n",
      "\tError from slot4@jupyter0000.chtc.wisc.edu: STARTER at 2607:f388:107c:501:216:3eff:fe0f:5959 failed to send file(s) to <[2607:f388:107c:501:216:3eff:fe0f:5959]:9618>: error reading from /var/lib/condor/execute/dir_1684033/e8a41bf8f29419bd7e9ee45ddab9fae1.out: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <[2607:f388:107c:501:216:3eff:fe0f:5959]:31528>\n",
      "\tCode 13 Subcode 2\n",
      "...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-262690545c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbad_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/htmap/result.py\u001b[0m in \u001b[0;36mtail\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "bad_result.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspect the stdout and stderr of each job using the `output` and `error` methods on the `MapResult`.\n",
    "The argument is the index of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landed on execute node karpel-1397.0-jupyter0000.chtc.wisc.edu (172.17.0.4) at 2018-10-04 14:59:15.816393\n",
      "Local directory contents:\n",
      "    /var/lib/condor/execute/dir_1682604/d238998870ae18a399d03477dad0c0a8.in\n",
      "    /var/lib/condor/execute/dir_1682604/_condor_stderr\n",
      "    /var/lib/condor/execute/dir_1682604/docker_stderror\n",
      "    /var/lib/condor/execute/dir_1682604/tmp\n",
      "    /var/lib/condor/execute/dir_1682604/var\n",
      "    /var/lib/condor/execute/dir_1682604/.job.ad\n",
      "    /var/lib/condor/execute/dir_1682604/_condor_stdout\n",
      "    /var/lib/condor/execute/dir_1682604/func\n",
      "    /var/lib/condor/execute/dir_1682604/.docker_sock\n",
      "    /var/lib/condor/execute/dir_1682604/.update.ad\n",
      "    /var/lib/condor/execute/dir_1682604/.machine.ad\n",
      "    /var/lib/condor/execute/dir_1682604/.chirp.config\n",
      "    /var/lib/condor/execute/dir_1682604/condor_exec.exe\n",
      "\n",
      "Running\n",
      "    <function bad at 0x7f6c57b7d730>\n",
      "with args\n",
      "    (0,)\n",
      "and kwargs\n",
      "    {}\n",
      "from input hash\n",
      "    d238998870ae18a399d03477dad0c0a8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bad_result.output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./condor_exec.exe\", line 87, in <module>\n",
      "    main(arg_hash = sys.argv[1])\n",
      "  File \"./condor_exec.exe\", line 81, in main\n",
      "    output = func(*args, **kwargs)\n",
      "  File \"<ipython-input-27-ed5913b3e3bc>\", line 3, in bad\n",
      "ZeroDivisionError: division by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bad_result.error(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we're able to debug the problem by looking at the exception remotely.\n",
    "\n",
    "Let's clean up the map so that we don't leave it dangling forever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_result.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
